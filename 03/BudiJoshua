---
title: "Ethics and Reproducibility..."
author: "Joshua Budi"
topic: "03"
layout: post
root: ../../../
---

## Background:

## Prompt:


In May 2015 Science retracted - without consent of the lead author - a paper on  how canvassers can sway people's opinions about gay marriage, 
see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour
The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect.<br>
The investigation resulting in the retraction was triggered by two  Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.
 
[FiveThirtyEight](https://fivethirtyeight.com/features/how-two-grad-students-uncovered-michael-lacour-fraud-and-a-way-to-change-opinions-on-transgender-rights/) has published an article with more details on the two Berkeley students' work.

Malicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. [Retraction Watch](https://retractionwatch.com/) is a data base that keeps track of retracted papers (see the related [Science magazine](https://www.sciencemag.org/news/2018/10/what-massive-database-retracted-papers-reveals-about-science-publishing-s-death-penalty) publication). 

Read the paper [Ten Simple Rules for Reproducible Computational Research](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285) by Sandve et al.


Write a blog post addressing the questions: 

1. **Pick one of the papers Retraction Watch features on their website and describe what went wrong**. 
I picked the number one most cited previously retracted paper with 1792 citations in under a year, before the retraction: Estruch, R., E. Ros, J. Salas-Salvadó, M.-I. Covas, D. Corella, et al. 2013. Primary Prevention of Cardiovascular Disease with a Mediterranean Diet. New England Journal of Medicine 368(14): 1279–1290.
The problem with the paper was that it failed to properly randomize the 11 baseline values from previous reports that they are comparing to. In 5 out of the 934 reports from other studies they are compiling, 
they mistakenly reported standard error of mean to be standard deviation. Although after reanalysis, the result did not change. 
In addition, there were some protocol deviations and enrollment of participants who did not get randomized treatment. 

2. **After reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not follow in your future projects.**
For me, Rule:9 Connect textual statements to underlying results would be quite a bit more intuitive to follow because I know that this is a good practice when we are running so many similar experiments 
that I am repeating. It is best to keep track what happens with each experiment, and if possible lay them all down in one document with the plots and text side by side (I started using OneNote lately for 
this and I love it!)

Rule 2: Avoiding manual data manipulation steps would be pretty hard to follow. In my research in plant pathology, my dataset happens to be small enough that it would be very tempting to just 
tweak things through excel one cell at a time. I try not to do this already because I am aware that this is mostly impractical when working with just slightly bigger dataset. It is even more tempting 
when there is just a lot of inconsistency in the plant growth measurements due to many factors or simple negligence in keeping all experimental unit the same, i.e. my single plants in 8oz styrofoam cups 
